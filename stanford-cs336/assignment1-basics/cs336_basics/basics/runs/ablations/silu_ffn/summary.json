{
  "experiment_name": "silu_ffn",
  "config": {
    "experiment_name": "silu_ffn",
    "experiment_id": "643f7401",
    "description": "Ablation: SiLU FFN instead of SwiGLU",
    "tags": [],
    "vocab_size": 10000,
    "context_length": 256,
    "d_model": 512,
    "num_layers": 4,
    "num_heads": 16,
    "d_ff": 2048,
    "rope_theta": 10000.0,
    "batch_size": 32,
    "max_iterations": 40000,
    "learning_rate": 0.0003,
    "min_learning_rate": 2.9999999999999997e-05,
    "warmup_iters": 400,
    "weight_decay": 0.1,
    "beta1": 0.9,
    "beta2": 0.999,
    "grad_clip": 1.0,
    "dataset": "TinyStories",
    "train_data_path": "cs336_basics/artifacts/datasets/tinystories_train_tokens.npy",
    "val_data_path": "cs336_basics/artifacts/datasets/tinystories_tokens.npy",
    "device": null,
    "dtype": "float32",
    "seed": 42,
    "log_interval": 50,
    "eval_interval": 400,
    "checkpoint_interval": 4000,
    "metadata": {
      "processed_tokens": 327680000,
      "use_layer_norm": true,
      "post_norm": false,
      "use_swiglu": false,
      "use_rope": true,
      "use_ablation_model": true
    }
  },
  "statistics": {
    "total_steps": 901,
    "total_wallclock_time": 7371.280181646347,
    "total_wallclock_hours": 2.0475778282350965,
    "train_loss": {
      "min": 1.2655495405197144,
      "max": 9.268219947814941,
      "mean": 1.6455170464515687,
      "final": 1.4475421905517578,
      "initial": 9.268219947814941
    },
    "val_loss": {
      "min": 1.4101348638534545,
      "max": 9.267081594467163,
      "mean": 1.6928413526256487,
      "final": 1.4115869760513307,
      "best": 1.4101348638534545
    }
  },
  "metrics_count": 901
}